---
title: "Baltimore Foot Traffic"
author: "Rob Wells"
date: "2025-01-22"
output: html_document
---
```{r}
library(tidyverse)
#remotes::install_github("walkerke/tidycensus")
library(tidyverse)
library(tidycensus)
#a = get_decennial(geography = "state", variables = "P1_001N", year = 2020)
# head(a, 5)
#install.packages("formattable")
library(formattable)
library(htmlwidgets)
#install.packages("leaflet")
library(leaflet)
library(sf)
library(formattable)
library(janitor)
#install.packages("leaflet.extras")
library(leaflet.extras)
library(googlesheets4)
```

It contains monthly foot traffic information for 20,000 stores in Baltimore City, Baltimore County, and Anne Arundel County from Jan to July 2024 (NAICS=44,45,71,72, 81). 
For each store, we have the aggregate foot traffic for the month, the same-month foot traffic last year, and the rate of change. You can also find information about the number of unique visitors and their proximityâ€”whether they are from nearby or outside the county.

#Import data
```{r}
#foot <- rio::import("../data/baltimore_foot_traffic.dta") - old
foot1 <- rio::import("../data/baltimore_foot_traffic_feb21_2025.dta")
#write.csv(foot1, "baltimore_foot_traffic.csv")
```

```{r}
glimpse(foot)
```

Dundalk zip code 21222
Edgemere 21219, 21052
Brandon Shores 21226

# Dundalk / Arundel
```{r}
#1671 results
focus <- foot1 |> 
  filter(postal_code == c("21222", "21219","21052", "21226", "21225", "21060", "21061", "21090"))
focus |> 
  count(city) |> 
  arrange(desc(n))
```

#Biggest losers

```{r}
losers <- focus |> 
  select(location_name, street_address, city, region, postal_code, chg_nvisits_yoy, start, placekey) |> 
  group_by(placekey) |> 
  slice_max(start, n=1) |> #select the most recent data if multiple entries
  ungroup() |> 
  arrange(chg_nvisits_yoy) |> 
  slice_min(chg_nvisits_yoy, n = 200) |>
  mutate(address = paste0(street_address, " ", city, " ", region, " ", postal_code)) |> 
  mutate(visit_drop = formattable::percent(chg_nvisits_yoy))

#write.csv(losers, "dundalk_arundel_losers.csv")


#fact check

# losers |> 
# count(location_name) |> 
# arrange(desc(n))

```




#Geocode Dundalk2
```{r}
library(tidyr)
library(ggmap)
register_google(key = "")


losers <- losers %>% 
  mutate(geo = geocode(address)) 

losers <- losers %>%
  tidyr::unnest(geo)


losers <- st_as_sf(losers, coords = c("lon", "lat"), crs = 4326)

# write.csv(losers, "dundalk_arundel_losers.csv")
```


#Map 
```{r}
leafMap <- leaflet() %>%
  addProviderTiles(providers$Esri.WorldStreetMap) %>%
  setView(lng = -76.52, lat = 39.27, zoom = 11.5) %>%
  addCircleMarkers(
    data = losers,
    radius = 8,
    color = "black",
    weight = 1,
    fillColor = ~pal(chg_nvisits_yoy),
    fillOpacity = 0.7,
    popup = ~paste("<b>", location_name, "</b><br>",
                  "Change in foot traffic: ", visit_drop, "<br>",
                  "For the time period", start, "<br>",
                  "Address: ", address)
  ) |> 
addControl(
    html = "<div style='background-color: white; padding: 0.0001px; border-radius: 0.0001px; text-align: center;'><h4 style='margin-bottom: 2px;'>Yearly Business Decline, Dundalk & Anne Arundel Co., since Key Bridge Collapse</h4><h5 style='margin-top: 0px;'>Click dot for business details</h5></div>",
    position = "topright"
  )
leafMap
saveWidget(leafMap, "../output/foot_traffic_decline_map_feb_2025.html")
```


#Earlier notes


```{r}
arundel <- foot |> 
  filter(postal_code == c("21225", "21226","21060", "21061", "21090", "21122"))

arundel |> 
  count(city) |> 
  arrange(desc(n))


```


```{r}
arundel_loser <- arundel |> 
  select(location_name, street_address, city, region, postal_code, dln_visits_yoy, start) |> 
  arrange(dln_visits_yoy) |> 
  slice_min(dln_visits_yoy, n = 100) |>
  mutate(foot_traffic_yoy = abs(dln_visits_yoy)) |> 
  mutate(address = paste0(street_address, " ", city, " ", region, " ", postal_code)) 
  


write.csv(arundel_loser, "arundel_loser.csv")
  


```


# Table
```{r}
library(kableExtra)
table_output <- losers %>%
  kbl(caption = "Baltimore Businesses Losing Customers") %>%
  kable_classic(full_width = F, html_font = "Cambria") %>%
  column_spec(1, bold = T, border_right = T) %>%
  column_spec(2, bold = F, border_right = T) |> 
  column_spec(3, width = "5em", background = "yellow") |> 
column_spec(4, bold = F, border_right = T) 

cat("<style>
    .caption {
      font-size: 30px !important;
    }
    </style>")
table_output


```
#Geocode Foot Traffic

Build lookup table: 16,475 entries
Foot has multiple entries for the same address
A lookup table will link back to the main database while saving the expense of geocoding 143,000 entries
```{r}
foot_sum <- foot |> 
  mutate(fulladdress = paste(street_address, city, region, postal_code, sep = ", ")) |> 
  distinct(fulladdress, .keep_all = TRUE)


```

### Geocode lookup table
```{r}
library(tidyr)
library(ggmap)
register_google(key = "")


foot_sum <- foot_sum %>% 
  mutate(geo = geocode(fulladdress)) 
write.csv(foot_sum, "foot_traffic_geocode_lookup.csv")

foot_sum <- foot_sum %>% 
  unnest(geo)

#Join with main data

foot_sum_short <- foot_sum |> 
  select(fulladdress, lon, lat)

foot1 <- foot |> 
  mutate(fulladdress = paste(street_address, city, region, postal_code, sep = ", ")) |>
  left_join(foot_sum_short, by=c("fulladdress"))

```

fact check
```{r}
sum(is.na(foot1$lat))

### total the places without lat lon
x <- foot1 |> 
  group_by(city) |> 
  count(is.na(lat)) |> 
  arrange(desc(n)) |> 
  rename(valid = 'is.na(lat)')

foot1 |> 
  group_by(city) |> 
  count() |> 
  arrange(desc(n))

```
#failed spatial join with business data
```{r}
bol <- read.csv("../data/baltimore_bol.csv") |> 
  janitor::clean_names() |> 
  select(company_name,       address_1,          address_2,         
city,               state,              zip,                zip4,              
latitude,           longitude,          phone,              fax,               
website,            email,              employees,          revenue,           
contact_formal_name,first_name,        
middle,             last_name,          suffix,             title,             
     last_published_date, classification, ranking_criteria, list_title, company_id, business_info) 

```

# spatial join
```{r}
foot_traffic_biz <- foot1 |>
  inner_join(bol, by = c("lat" = "latitude", "lon" = "longitude"))

```

# Unemployment Data

```{r}
unem_feb <- rio::import("/Users/robwells/Downloads/Unemployment_Feb2024_March2024.xlsx", sheet="Feb2024" ) |> 
  janitor::clean_names() |> 
  rename(feb_count = count) |> 
   filter(state_code_value=="MD")

unem_march <- rio::import("/Users/robwells/Downloads/Unemployment_Feb2024_March2024.xlsx", sheet="March 2024") |> 
  janitor::clean_names() |> 
  rename(march_count = count) |> 
   filter(state_code_value=="MD")

combined_unem <- unem_feb |> 
  inner_join(unem_march, by=c("zip", "year", "state_code_value")) |> 
  mutate(diff_march_feb = (march_count-feb_count))

write.csv(combined_unem, "combined_unem_feb_march_2024.csv")

```

```{r}

unem_feb |> 
  count(state_code_value) |> 
  arrange(desc(n)) |> 
  filter(state_code_value=="MD")


```

```{r}
unem_march |> 
  count(state_code_value) |> 
  arrange(desc(n))
```

```{r}

combined_unem |> 
  count(state_code_value) |> 
  arrange(desc(n))
```

